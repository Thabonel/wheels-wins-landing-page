# PAM Model Hot-Swap System

**Zero-Downtime AI Model Switching**

## üéØ Problem Solved

AI models change constantly:
- GPT-4o was discontinued, then brought back
- New models release monthly (Haiku 4.5 just launched)
- Model deprecations happen with short notice
- Can't have SaaS going down when model changes

## ‚úÖ Solution: Hot-Swap System

**Switch AI models instantly without restarting backend or deploying code.**

Three ways to switch models:
1. **Environment Variables** (Recommended - persistent)
2. **Admin API** (Instant - temporary until restart)
3. **Automatic Failover** (Self-healing when models fail)

---

## üìã Quick Start

### Option 1: Environment Variables (Persistent)

**Change models via Render dashboard** (no code deploy needed):

1. Go to: https://dashboard.render.com/web/srv-XXXXX/env
2. Add/update these variables:
   ```bash
   PAM_PRIMARY_MODEL=claude-haiku-4-5-20250514
   PAM_FALLBACK_MODEL_1=claude-3-5-haiku-20241022
   PAM_FALLBACK_MODEL_2=gemini-1.5-flash-latest
   PAM_FALLBACK_MODEL_3=gpt-4o-mini
   ```
3. Click "Save Changes"
4. **No restart needed!** Models switch on next PAM request

### Option 2: Admin API (Instant Temporary Change)

**Change models via API call** (admin only):

```bash
# View current config
curl https://pam-backend.onrender.com/api/v1/admin/models/config \
  -H "Authorization: Bearer <ADMIN_JWT_TOKEN>"

# Change primary model instantly
curl -X POST https://pam-backend.onrender.com/api/v1/admin/models/set-primary \
  -H "Authorization: Bearer <ADMIN_JWT_TOKEN>" \
  -H "Content-Type: application/json" \
  -d '{"model_id": "claude-haiku-4-5-20250514"}'

# Reload config from environment
curl -X POST https://pam-backend.onrender.com/api/v1/admin/models/reload \
  -H "Authorization: Bearer <ADMIN_JWT_TOKEN>" \
  -H "Content-Type: application/json" \
  -d '{"force": false}'
```

### Option 3: Automatic Failover

**System automatically fails over when models break:**

```
Request 1: claude-sonnet-4-5 (primary) ‚Üí Success ‚úÖ
Request 2: claude-sonnet-4-5 ‚Üí FAIL (model deprecated) ‚ùå
          ‚Üí Auto failover to claude-3-5-haiku ‚úÖ
Request 3: claude-3-5-haiku ‚Üí Success ‚úÖ
          ‚Üí Primary marked unhealthy for 5 minutes
```

---

## üèóÔ∏è Architecture

### Model Configuration File

**Location:** `backend/app/config/model_config.py`

```python
# Known model registry (update as new models release)
MODEL_REGISTRY = {
    "claude-sonnet-4-5-20250929": {...},    # Best quality
    "claude-haiku-4-5-20250514": {...},     # NEW: Fast + cheap + capable
    "claude-3-5-haiku-20241022": {...},     # Previous Haiku
    "gemini-1.5-flash-latest": {...},       # Extremely cheap fallback
    "gpt-4o": {...},                        # OpenAI fallback
}
```

### How It Works

1. **PAM Initialization:**
   ```python
   # PAM reads primary model from environment
   model_config = get_model_config()
   primary_model = model_config.get_primary_model()
   self.model = primary_model.model_id
   ```

2. **Failover Chain:**
   ```python
   # On API error, try next model automatically
   try:
       response = await claude_api(model=current_model)
   except:
       next_model = model_config.get_next_model(current_model)
       response = await claude_api(model=next_model.model_id)
   ```

3. **Health Monitoring:**
   ```python
   # Failed models marked unhealthy for 5 minutes
   model_config.mark_model_unhealthy(model_id, duration_minutes=5)
   ```

---

## üìä Available Models

### Anthropic Claude Models

| Model ID | Name | Cost (Input/Output) | Use Case |
|----------|------|---------------------|----------|
| `claude-sonnet-4-5-20250929` | Sonnet 4.5 | $3/$15 per 1M tokens | Best quality, current default |
| `claude-haiku-4-5-20250514` | Haiku 4.5 | $1/$5 per 1M tokens | **NEW: Ideal for PAM** (fast + cheap + capable) |
| `claude-3-5-haiku-20241022` | Haiku 3.5 | $1/$5 per 1M tokens | Previous Haiku |
| `claude-3-7-sonnet-20250219` | Sonnet 3.7 | $3/$15 per 1M tokens | Previous Sonnet |
| `claude-opus-4-20250514` | Opus 4 | $15/$75 per 1M tokens | Most powerful (expensive) |

### Google Gemini Models

| Model ID | Name | Cost (Input/Output) | Use Case |
|----------|------|---------------------|----------|
| `gemini-1.5-flash-latest` | Gemini Flash | $0.075/$0.30 per 1M tokens | Extremely cheap fallback |
| `gemini-1.5-pro-latest` | Gemini Pro | $1.25/$5 per 1M tokens | Good quality, huge context |

### OpenAI Models

| Model ID | Name | Cost (Input/Output) | Use Case |
|----------|------|---------------------|----------|
| `gpt-4o` | GPT-4o | $2.5/$10 per 1M tokens | OpenAI flagship |
| `gpt-4o-mini` | GPT-4o Mini | $0.15/$0.60 per 1M tokens | Cheap OpenAI option |

---

## üîß Admin API Endpoints

### GET `/api/v1/admin/models/config`

View current model configuration

**Response:**
```json
{
  "primary_model": {
    "id": "claude-sonnet-4-5-20250929",
    "config": {...},
    "healthy": true
  },
  "fallback_models": [
    {"id": "claude-3-5-haiku-20241022", "healthy": true},
    {"id": "gemini-1.5-flash-latest", "healthy": true}
  ],
  "total_models": 3,
  "healthy_models": 3
}
```

### POST `/api/v1/admin/models/reload`

Reload configuration from environment (hot-swap)

**Request:**
```json
{
  "force": false
}
```

### POST `/api/v1/admin/models/set-primary`

Change primary model instantly

**Request:**
```json
{
  "model_id": "claude-haiku-4-5-20250514",
  "update_env": false
}
```

**Warning:** If `update_env=false`, change is temporary until restart.

### GET `/api/v1/admin/models/available`

List all available models

**Response:**
```json
[
  {
    "model_id": "claude-haiku-4-5-20250514",
    "name": "Claude Haiku 4.5",
    "provider": "anthropic",
    "cost_per_1m_input": 1.0,
    "cost_per_1m_output": 5.0,
    "description": "Latest Haiku - ideal for PAM (fast + cheap + capable)"
  }
]
```

### GET `/api/v1/admin/models/health`

Check health status of all models

**Response:**
```json
[
  {
    "model_id": "claude-sonnet-4-5-20250929",
    "model_name": "Claude Sonnet 4.5",
    "provider": "anthropic",
    "is_healthy": true,
    "cost_per_1m_input": 3.0,
    "supports_tools": true
  }
]
```

---

## üö® Emergency Procedures

### Model Deprecated Suddenly

**Scenario:** Anthropic deprecates claude-sonnet-4-5 with 48 hours notice

**Solution 1: Instant Switch (Temporary)**
```bash
curl -X POST https://pam-backend.onrender.com/api/v1/admin/models/set-primary \
  -H "Authorization: Bearer <ADMIN_JWT_TOKEN>" \
  -d '{"model_id": "claude-haiku-4-5-20250514"}'
```
Changes take effect immediately, SaaS stays online.

**Solution 2: Permanent Switch (Recommended)**
1. Update environment variable `PAM_PRIMARY_MODEL=claude-haiku-4-5-20250514`
2. Call reload endpoint or restart backend

### All Models Failing

**Scenario:** API outage affecting all providers

**What Happens:**
1. PAM tries primary model ‚Üí fails
2. PAM tries fallback 1 ‚Üí fails
3. PAM tries fallback 2 ‚Üí fails
4. PAM returns error to user (graceful degradation)
5. All models marked unhealthy for 5 minutes
6. After 5 minutes, health cache expires, retries primary

**Manual Override:**
```bash
# Force reload to reset health cache
curl -X POST https://pam-backend.onrender.com/api/v1/admin/models/reload \
  -H "Authorization: Bearer <ADMIN_JWT_TOKEN>" \
  -d '{"force": true}'
```

---

## üí∞ Cost Optimization

### Recommended Configuration (Cost-Optimized)

```bash
PAM_PRIMARY_MODEL=claude-haiku-4-5-20250514   # $1/$5 (67% cheaper than Sonnet)
PAM_FALLBACK_MODEL_1=gemini-1.5-flash-latest  # $0.075/$0.30 (98% cheaper)
PAM_FALLBACK_MODEL_2=gpt-4o-mini              # $0.15/$0.60 (95% cheaper)
```

**Estimated Savings:** 67% reduction in AI costs

### Recommended Configuration (Quality-Optimized)

```bash
PAM_PRIMARY_MODEL=claude-sonnet-4-5-20250929  # Best quality
PAM_FALLBACK_MODEL_1=claude-haiku-4-5-20250514 # Fast failover
PAM_FALLBACK_MODEL_2=gpt-4o                   # Different provider
```

**Reliability:** 99.9% uptime even if one provider has outage

---

## üß™ Testing

### Test Model Switch

```bash
# 1. Check current model
curl https://pam-backend.onrender.com/api/v1/admin/models/config \
  -H "Authorization: Bearer <ADMIN_JWT_TOKEN>"

# 2. Switch to Haiku 4.5
curl -X POST https://pam-backend.onrender.com/api/v1/admin/models/set-primary \
  -H "Authorization: Bearer <ADMIN_JWT_TOKEN>" \
  -d '{"model_id": "claude-haiku-4-5-20250514"}'

# 3. Test PAM with new model
curl https://pam-backend.onrender.com/api/v1/pam/chat \
  -H "Authorization: Bearer <USER_JWT_TOKEN>" \
  -d '{"message": "Hello PAM, what model are you using?"}'

# 4. Verify in response metadata
# Should show: "source": "claude_pam_primary", "model": "claude-haiku-4-5-20250514"
```

### Test Automatic Failover

**Simulate model failure:**
```bash
# 1. Set invalid model as primary (will fail)
curl -X POST https://pam-backend.onrender.com/api/v1/admin/models/set-primary \
  -H "Authorization: Bearer <ADMIN_JWT_TOKEN>" \
  -d '{"model_id": "invalid-model-id"}'

# 2. Send PAM request
# Should automatically fail over to fallback model
curl https://pam-backend.onrender.com/api/v1/pam/chat \
  -H "Authorization: Bearer <USER_JWT_TOKEN>" \
  -d '{"message": "Test failover"}'

# 3. Check logs - should show:
# "‚ö†Ô∏è Model invalid-model-id failed on attempt 1"
# "üîÑ Failing over to Claude Haiku 3.5"
# "‚úÖ Claude API response received from claude-3-5-haiku-20241022"
```

---

## üìù Adding New Models

When new models release (e.g., Claude Opus 5):

1. **Update Model Registry:**
   ```python
   # backend/app/config/model_config.py
   MODEL_REGISTRY["claude-opus-5-20260101"] = ModelConfig(
       name="Claude Opus 5",
       provider="anthropic",
       model_id="claude-opus-5-20260101",
       cost_per_1m_input=20.0,
       cost_per_1m_output=100.0,
       max_tokens=200000,
       supports_tools=True,
       supports_streaming=True,
       description="Next-gen Opus - experimental"
   )
   ```

2. **Deploy Code:**
   ```bash
   git add backend/app/config/model_config.py
   git commit -m "feat: add Claude Opus 5 model support"
   git push origin staging
   ```

3. **Switch Without Downtime:**
   ```bash
   # After deploy completes
   curl -X POST https://pam-backend.onrender.com/api/v1/admin/models/set-primary \
     -H "Authorization: Bearer <ADMIN_JWT_TOKEN>" \
     -d '{"model_id": "claude-opus-5-20260101"}'
   ```

---

## üîê Security

**Admin Endpoints Require Authentication:**
- All `/admin/models/*` endpoints require valid admin JWT
- Uses `require_admin` dependency (checks user role)
- Unauthorized requests return 401/403

**Environment Variables:**
- Never expose `ANTHROPIC_API_KEY` in model config
- Keys stored in Render secure environment variables
- Model IDs are public information (safe to expose)

---

## üìä Monitoring

**Health Check:**
```bash
# Check which models are healthy
curl https://pam-backend.onrender.com/api/v1/admin/models/health \
  -H "Authorization: Bearer <ADMIN_JWT_TOKEN>"
```

**Backend Logs:**
```
PAM using model: Claude Haiku 4.5 (claude-haiku-4-5-20250514)
üß† [Attempt 1/3] Calling Claude API with 40 tools...
‚úÖ Claude API response received from claude-haiku-4-5-20250514 in 1250.5ms
```

---

## üéØ Best Practices

1. **Set Fallback Chain:**
   - Always configure at least 2 fallback models
   - Use different providers (Anthropic, Google, OpenAI) for redundancy

2. **Monitor Costs:**
   - Track token usage in admin dashboard
   - Switch to cheaper models during high-volume periods

3. **Test Before Switching:**
   - Use temporary switch first (`update_env=false`)
   - Test with real users
   - Make permanent (`update_env=true`) after validation

4. **Document Changes:**
   - Update MODEL_REGISTRY when new models release
   - Add deprecation warnings for old models

---

## üìö Related Documentation

- **Model Config Code:** `backend/app/config/model_config.py`
- **PAM Core:** `backend/app/services/pam/core/pam.py`
- **Admin API:** `backend/app/api/v1/admin/model_config.py`
- **Environment Setup:** Render dashboard ‚Üí Environment tab

---

**Last Updated:** October 16, 2025
**Maintainer:** PAM Development Team
**Status:** Production Ready ‚úÖ
